WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
Falling back to Fairscale checkpoint
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
WARNING:root:Pytorch pre-release version 1.12.0a0+gita4ad332 - assuming intent to test it
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.0994990234375 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.8677969970703125 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.083472412109375 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.8793425903320312 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.043464599609375 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.8715765991210938 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.20505615234375 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.8721336059570313 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
Wrapping Embedding(3072, 5184)
Got meta module Embedding(3072, 5184)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping EmbeddingStem(
  (tok_emb): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Embedding(3072, 5184)
    )
  )
  (drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module EmbeddingStem(
  (tok_emb): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Embedding(3072, 5184)
    )
  )
  (drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=5184, bias=True)
Got meta module Linear(in_features=5184, out_features=5184, bias=True)
Materializing it on 0
Wrapping CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Got meta module CausalSelfAttention(
  (key): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (query): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (value): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
  (attn_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (resid_drop): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
  (proj): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
    )
  )
)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Got meta module Linear(in_features=5184, out_features=20736, bias=True)
Materializing it on 0
Wrapping GELU(approximate=none)
Got meta module GELU(approximate=none)
Materializing it on 0
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Got meta module Linear(in_features=20736, out_features=5184, bias=True)
Materializing it on 0
Wrapping Dropout(p=0.1, inplace=False)
Got meta module Dropout(p=0.1, inplace=False)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): GELU(approximate=none)
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Dropout(p=0.1, inplace=False)
    )
  )
)
Materializing it on 0
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Got meta module Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (query): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (value): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
        (attn_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (resid_drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
        (proj): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
          )
        )
      )
    )
  )
  (mlp): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): GELU(approximate=none)
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (4): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (5): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (6): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (7): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (8): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (9): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (10): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (11): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (12): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (13): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (14): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (15): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (16): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (17): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (18): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (19): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (20): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (21): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (22): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (23): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (24): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (25): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (26): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (27): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (28): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (29): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (30): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (31): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (32): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (33): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (34): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (35): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (36): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (37): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (38): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (39): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (40): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (41): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (42): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (43): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (44): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (45): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (46): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (47): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
)
Got meta module Sequential(
  (0): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (3): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (4): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (5): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (6): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (7): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (8): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (9): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (10): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (11): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (12): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (13): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (14): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (15): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (16): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (17): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (18): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (19): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (20): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (21): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (22): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (23): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (24): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (25): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (26): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (27): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (28): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (29): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (30): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (31): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (32): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (33): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (34): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (35): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (36): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (37): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (38): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (39): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (40): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (41): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (42): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (43): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (44): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (45): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (46): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
  (47): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Block(
        (ln1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (ln2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
          )
        )
        (attn): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): CausalSelfAttention(
              (key): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (query): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (value): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
              (attn_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (resid_drop): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
              (proj): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                )
              )
            )
          )
        )
        (mlp): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Sequential(
              (0): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                )
              )
              (1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): GELU(approximate=none)
                )
              )
              (2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                )
              )
              (3): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Dropout(p=0.1, inplace=False)
                )
              )
            )
          )
        )
      )
    )
  )
)
Materializing it on 0
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Got meta module LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Materializing it on 0
Wrapping Linear(in_features=5184, out_features=3072, bias=False)
Got meta module Linear(in_features=5184, out_features=3072, bias=False)
Materializing it on 0
Wrapping ShardedGPT(
  (emb_stem): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): EmbeddingStem(
        (tok_emb): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Embedding(3072, 5184)
          )
        )
        (drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (blocks): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (4): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (5): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (6): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (7): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (8): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (9): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (10): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (11): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (12): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (13): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (14): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (15): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (16): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (17): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (18): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (19): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (20): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (21): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (22): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (23): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (24): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (25): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (26): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (27): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (28): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (29): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (30): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (31): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (32): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (33): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (34): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (35): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (36): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (37): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (38): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (39): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (40): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (41): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (42): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (43): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (44): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (45): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (46): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (47): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
    )
  )
  (ln_f): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (head): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
    )
  )
)
Got meta module ShardedGPT(
  (emb_stem): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): EmbeddingStem(
        (tok_emb): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Embedding(3072, 5184)
          )
        )
        (drop): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (blocks): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Sequential(
        (0): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (1): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (2): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (3): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (4): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (5): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (6): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (7): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (8): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (9): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (10): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (11): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (12): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (13): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (14): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (15): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (16): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (17): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (18): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (19): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (20): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (21): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (22): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (23): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (24): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (25): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (26): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (27): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (28): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (29): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (30): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (31): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (32): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (33): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (34): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (35): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (36): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (37): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (38): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (39): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (40): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (41): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (42): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (43): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (44): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (45): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (46): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
        (47): FullyShardedDataParallel(
          (_fsdp_wrapped_module): FlattenParamsWrapper(
            (_fpw_module): Block(
              (ln1): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (ln2): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                )
              )
              (attn): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): CausalSelfAttention(
                    (key): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (query): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (value): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                    (attn_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (resid_drop): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                    (proj): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                      )
                    )
                  )
                )
              )
              (mlp): FullyShardedDataParallel(
                (_fsdp_wrapped_module): FlattenParamsWrapper(
                  (_fpw_module): Sequential(
                    (0): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                      )
                    )
                    (1): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): GELU(approximate=none)
                      )
                    )
                    (2): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                      )
                    )
                    (3): FullyShardedDataParallel(
                      (_fsdp_wrapped_module): FlattenParamsWrapper(
                        (_fpw_module): Dropout(p=0.1, inplace=False)
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
    )
  )
  (ln_f): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (head): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
    )
  )
)
Materializing it on 0
deferred build time: 4.17345849609375 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
Wrapping EmbeddingStem(
  (tok_emb): Embedding(3072, 5184)
  (drop): Dropout(p=0.1, inplace=False)
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping CausalSelfAttention(
  (key): Linear(in_features=5184, out_features=5184, bias=True)
  (query): Linear(in_features=5184, out_features=5184, bias=True)
  (value): Linear(in_features=5184, out_features=5184, bias=True)
  (attn_drop): Dropout(p=0.1, inplace=False)
  (resid_drop): Dropout(p=0.1, inplace=False)
  (proj): Linear(in_features=5184, out_features=5184, bias=True)
)
Wrapping Linear(in_features=5184, out_features=20736, bias=True)
Wrapping Linear(in_features=20736, out_features=5184, bias=True)
Wrapping Block(
  (ln1): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (ln2): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (attn): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): CausalSelfAttention(
        (key): Linear(in_features=5184, out_features=5184, bias=True)
        (query): Linear(in_features=5184, out_features=5184, bias=True)
        (value): Linear(in_features=5184, out_features=5184, bias=True)
        (attn_drop): Dropout(p=0.1, inplace=False)
        (resid_drop): Dropout(p=0.1, inplace=False)
        (proj): Linear(in_features=5184, out_features=5184, bias=True)
      )
    )
  )
  (mlp): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
      )
    )
    (1): GELU(approximate=none)
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
      )
    )
    (3): Dropout(p=0.1, inplace=False)
  )
)
Wrapping LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
Wrapping Linear(in_features=5184, out_features=3072, bias=False)
number of parameters: 1939387536
Wrapping ShardedGPT(
  (emb_stem): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): EmbeddingStem(
        (tok_emb): Embedding(3072, 5184)
        (drop): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (blocks): Sequential(
    (0): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (1): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (2): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (3): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (4): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (5): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (6): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (7): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (8): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (9): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (10): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (11): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (12): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (13): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (14): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (15): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (16): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (17): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (18): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (19): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (20): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (21): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (22): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (23): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (24): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (25): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (26): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (27): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (28): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (29): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (30): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (31): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (32): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (33): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (34): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (35): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (36): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (37): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (38): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (39): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (40): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (41): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (42): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (43): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (44): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (45): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (46): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (47): FullyShardedDataParallel(
      (_fsdp_wrapped_module): FlattenParamsWrapper(
        (_fpw_module): Block(
          (ln1): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (ln2): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
            )
          )
          (attn): FullyShardedDataParallel(
            (_fsdp_wrapped_module): FlattenParamsWrapper(
              (_fpw_module): CausalSelfAttention(
                (key): Linear(in_features=5184, out_features=5184, bias=True)
                (query): Linear(in_features=5184, out_features=5184, bias=True)
                (value): Linear(in_features=5184, out_features=5184, bias=True)
                (attn_drop): Dropout(p=0.1, inplace=False)
                (resid_drop): Dropout(p=0.1, inplace=False)
                (proj): Linear(in_features=5184, out_features=5184, bias=True)
              )
            )
          )
          (mlp): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
              )
            )
            (1): GELU(approximate=none)
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
              )
            )
            (3): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (ln_f): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
    )
  )
  (head): FullyShardedDataParallel(
    (_fsdp_wrapped_module): FlattenParamsWrapper(
      (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
    )
  )
)
regular build time: 0.8836618041992188 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.14222314453125 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.8769577026367188 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.057619384765625 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.8955924682617188 sec
Initialized both FSDP models
Falling back to Fairscale checkpoint
number of parameters: 15515100288
deferred build time: 4.24787158203125 sec
FullyShardedDataParallel(
  (_fsdp_wrapped_module): FlattenParamsWrapper(
    (_fpw_module): ShardedGPT(
      (emb_stem): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): EmbeddingStem(
            (tok_emb): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Embedding(3072, 5184)
              )
            )
            (drop): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
      )
      (blocks): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Sequential(
            (0): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (1): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (2): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (3): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (4): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (5): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (6): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (7): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (8): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (9): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (10): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (11): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (12): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (13): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (14): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (15): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (16): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (17): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (18): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (19): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (20): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (21): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (22): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (23): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (24): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (25): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (26): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (27): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (28): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (29): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (30): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (31): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (32): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (33): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (34): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (35): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (36): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (37): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (38): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (39): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (40): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (41): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (42): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (43): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (44): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (45): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (46): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
            (47): FullyShardedDataParallel(
              (_fsdp_wrapped_module): FlattenParamsWrapper(
                (_fpw_module): Block(
                  (ln1): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (ln2): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
                    )
                  )
                  (attn): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): CausalSelfAttention(
                        (key): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (query): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (value): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                        (attn_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (resid_drop): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                        (proj): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=5184, bias=True)
                          )
                        )
                      )
                    )
                  )
                  (mlp): FullyShardedDataParallel(
                    (_fsdp_wrapped_module): FlattenParamsWrapper(
                      (_fpw_module): Sequential(
                        (0): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=5184, out_features=20736, bias=True)
                          )
                        )
                        (1): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): GELU(approximate=none)
                          )
                        )
                        (2): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Linear(in_features=20736, out_features=5184, bias=True)
                          )
                        )
                        (3): FullyShardedDataParallel(
                          (_fsdp_wrapped_module): FlattenParamsWrapper(
                            (_fpw_module): Dropout(p=0.1, inplace=False)
                          )
                        )
                      )
                    )
                  )
                )
              )
            )
          )
        )
      )
      (ln_f): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): LayerNorm((5184,), eps=1e-05, elementwise_affine=True)
        )
      )
      (head): FullyShardedDataParallel(
        (_fsdp_wrapped_module): FlattenParamsWrapper(
          (_fpw_module): Linear(in_features=5184, out_features=3072, bias=False)
        )
      )
    )
  )
)
number of parameters: 1939387536
regular build time: 0.885190673828125 sec
Initialized both FSDP models
